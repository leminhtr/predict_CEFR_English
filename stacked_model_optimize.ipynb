{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from vecstack import stacking\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sentences', 'words', 'letters.all', 'syllables', 'punct',\n",
       "       'avg.sentc.length', 'avg.word.length', 'avg.syll.word',\n",
       "       'sntc.per.word', 'TTR', 'ARI', 'Bormuth', 'Coleman.C1',\n",
       "       'Coleman.C2', 'Coleman.C3', 'Coleman.C4', 'Coleman.Liau',\n",
       "       'Dale.Chall', 'Danielson.Bryan.DB1', 'Danielson.Bryan.DB2',\n",
       "       'Dickes.Steiwer', 'DRP', 'ELF', 'Farr.Jenkins.Paterson', 'Flesch',\n",
       "       'Flesch.Kincaid', 'FOG', 'FORCAST', 'Fucks', 'Linsear.Write',\n",
       "       'LIX', 'nWS1', 'nWS2', 'nWS3', 'nWS4', 'RIX', 'SMOG', 'Spache',\n",
       "       'Strain', 'Traenkle.Bailer.TB1', 'Traenkle.Bailer.TB2', 'TRI',\n",
       "       'Tuldava', 'Wheeler.Smith', 'text', 'CTTR', 'HD-D (vocd-D)',\n",
       "       \"Herdan's C\", 'Maas a', 'Maas lgV0', 'MATTR', 'MSTTR', 'MTLD',\n",
       "       'Root TTR', 'Summer', 'TTR.1', 'Uber index', \"Yule's K\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = pd.read_csv(\"../train_cap2018.csv\")\n",
    "(nrow_default, ncol_default) = train_set.shape\n",
    "features_list_default = train_set.columns.values[1:ncol_default-1]\n",
    "features_list_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop string values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(df):\n",
    "    df = df.drop('fulltext', axis = 1)\n",
    "    df = df.drop('MATTR', axis=1)\n",
    "    df = df.drop('MSTTR', axis=1)\n",
    "    return df\n",
    "\n",
    "def split_df_to_data_target(df):\n",
    "    # Get list of features w/o feature containing string values\n",
    "    (nrow, ncol) = df.shape\n",
    "    features = df.columns.values[0:ncol-1]\n",
    "\n",
    "    # Separating out the features\n",
    "    x = df.loc[:, features].values\n",
    "\n",
    "    # Separating out the target\n",
    "    y = df.loc[:,['level1']].values\n",
    "    return x,y\n",
    "\n",
    "def standard_scale_x_data(x):\n",
    "    return StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = prepare_data(df)\n",
    "x, y = split_df_to_data_target(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(nrow, ncol) = df.shape\n",
    "ncol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropping MATTR & MSTTR columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of features w/o feature containing string values\n",
    "(nrow, ncol) = df.shape\n",
    "features = df.columns.values[0:ncol-1]\n",
    "\n",
    "\n",
    "# Separating out the features\n",
    "x = df.loc[:, features].values\n",
    "\n",
    "# Separating out the target\n",
    "y = df.loc[:,['level1']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentences</th>\n",
       "      <th>words</th>\n",
       "      <th>letters.all</th>\n",
       "      <th>syllables</th>\n",
       "      <th>punct</th>\n",
       "      <th>avg.sentc.length</th>\n",
       "      <th>avg.word.length</th>\n",
       "      <th>avg.syll.word</th>\n",
       "      <th>sntc.per.word</th>\n",
       "      <th>TTR</th>\n",
       "      <th>...</th>\n",
       "      <th>HD-D (vocd-D)</th>\n",
       "      <th>Herdan's C</th>\n",
       "      <th>Maas a</th>\n",
       "      <th>Maas lgV0</th>\n",
       "      <th>MTLD</th>\n",
       "      <th>Root TTR</th>\n",
       "      <th>Summer</th>\n",
       "      <th>TTR.1</th>\n",
       "      <th>Uber index</th>\n",
       "      <th>Yule's K</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27310.000000</td>\n",
       "      <td>27310.000000</td>\n",
       "      <td>27310.000000</td>\n",
       "      <td>27310.000000</td>\n",
       "      <td>27310.000000</td>\n",
       "      <td>27310.000000</td>\n",
       "      <td>27310.000000</td>\n",
       "      <td>27310.000000</td>\n",
       "      <td>27310.000000</td>\n",
       "      <td>27310.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>27310.000000</td>\n",
       "      <td>27310.000000</td>\n",
       "      <td>27310.000000</td>\n",
       "      <td>27310.000000</td>\n",
       "      <td>27310.000000</td>\n",
       "      <td>27310.000000</td>\n",
       "      <td>27310.000000</td>\n",
       "      <td>27310.000000</td>\n",
       "      <td>27310.000000</td>\n",
       "      <td>27310.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.178103</td>\n",
       "      <td>69.591578</td>\n",
       "      <td>286.920871</td>\n",
       "      <td>94.919443</td>\n",
       "      <td>13.445405</td>\n",
       "      <td>13.808023</td>\n",
       "      <td>4.068831</td>\n",
       "      <td>1.342988</td>\n",
       "      <td>0.102530</td>\n",
       "      <td>0.723658</td>\n",
       "      <td>...</td>\n",
       "      <td>29.973272</td>\n",
       "      <td>0.919785</td>\n",
       "      <td>0.209477</td>\n",
       "      <td>4.362110</td>\n",
       "      <td>60.654317</td>\n",
       "      <td>5.621359</td>\n",
       "      <td>0.839242</td>\n",
       "      <td>0.723612</td>\n",
       "      <td>25.751004</td>\n",
       "      <td>175.234313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.565665</td>\n",
       "      <td>41.665862</td>\n",
       "      <td>183.019658</td>\n",
       "      <td>60.276153</td>\n",
       "      <td>7.705855</td>\n",
       "      <td>11.104274</td>\n",
       "      <td>0.499349</td>\n",
       "      <td>0.145937</td>\n",
       "      <td>0.061869</td>\n",
       "      <td>0.101662</td>\n",
       "      <td>...</td>\n",
       "      <td>6.041291</td>\n",
       "      <td>0.029880</td>\n",
       "      <td>0.038736</td>\n",
       "      <td>0.985314</td>\n",
       "      <td>29.939369</td>\n",
       "      <td>1.308844</td>\n",
       "      <td>0.097361</td>\n",
       "      <td>0.101676</td>\n",
       "      <td>13.431118</td>\n",
       "      <td>96.680399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.437500</td>\n",
       "      <td>2.230769</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.005435</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>5.360000</td>\n",
       "      <td>1.770000</td>\n",
       "      <td>-2.510000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>11.340000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>149.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.741098</td>\n",
       "      <td>1.243590</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>...</td>\n",
       "      <td>27.382500</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>3.730000</td>\n",
       "      <td>39.675000</td>\n",
       "      <td>4.620000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>18.750000</td>\n",
       "      <td>110.190000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>83.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4.028037</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>...</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>4.310000</td>\n",
       "      <td>55.070000</td>\n",
       "      <td>5.530000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.710000</td>\n",
       "      <td>23.020000</td>\n",
       "      <td>152.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>4.343750</td>\n",
       "      <td>1.427251</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.791667</td>\n",
       "      <td>...</td>\n",
       "      <td>34.220000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>4.840000</td>\n",
       "      <td>75.400000</td>\n",
       "      <td>6.560000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>28.560000</td>\n",
       "      <td>214.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>464.000000</td>\n",
       "      <td>2050.000000</td>\n",
       "      <td>654.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>184.000000</td>\n",
       "      <td>9.913043</td>\n",
       "      <td>3.173913</td>\n",
       "      <td>0.695652</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>...</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>14.230000</td>\n",
       "      <td>493.920000</td>\n",
       "      <td>11.930000</td>\n",
       "      <td>3.510000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>251.780000</td>\n",
       "      <td>1564.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          sentences         words   letters.all     syllables         punct  \\\n",
       "count  27310.000000  27310.000000  27310.000000  27310.000000  27310.000000   \n",
       "mean       6.178103     69.591578    286.920871     94.919443     13.445405   \n",
       "std        3.565665     41.665862    183.019658     60.276153      7.705855   \n",
       "min        1.000000      5.000000     21.000000      6.000000      0.000000   \n",
       "25%        4.000000     38.000000    149.000000     49.000000      8.000000   \n",
       "50%        6.000000     62.000000    250.000000     83.000000     12.000000   \n",
       "75%        8.000000     92.000000    380.000000    125.000000     17.000000   \n",
       "max       50.000000    464.000000   2050.000000    654.000000    122.000000   \n",
       "\n",
       "       avg.sentc.length  avg.word.length  avg.syll.word  sntc.per.word  \\\n",
       "count      27310.000000     27310.000000   27310.000000   27310.000000   \n",
       "mean          13.808023         4.068831       1.342988       0.102530   \n",
       "std           11.104274         0.499349       0.145937       0.061869   \n",
       "min            1.437500         2.230769       1.000000       0.005435   \n",
       "25%            8.000000         3.741098       1.243590       0.064516   \n",
       "50%           11.000000         4.028037       1.333333       0.090909   \n",
       "75%           15.500000         4.343750       1.427251       0.125000   \n",
       "max          184.000000         9.913043       3.173913       0.695652   \n",
       "\n",
       "                TTR      ...       HD-D (vocd-D)    Herdan's C        Maas a  \\\n",
       "count  27310.000000      ...        27310.000000  27310.000000  27310.000000   \n",
       "mean       0.723658      ...           29.973272      0.919785      0.209477   \n",
       "std        0.101662      ...            6.041291      0.029880      0.038736   \n",
       "min        0.294118      ...            4.000000      0.720000      0.060000   \n",
       "25%        0.652174      ...           27.382500      0.900000      0.190000   \n",
       "50%        0.714286      ...           32.000000      0.920000      0.210000   \n",
       "75%        0.791667      ...           34.220000      0.940000      0.230000   \n",
       "max        0.976190      ...           41.000000      0.990000      0.500000   \n",
       "\n",
       "          Maas lgV0          MTLD      Root TTR        Summer         TTR.1  \\\n",
       "count  27310.000000  27310.000000  27310.000000  27310.000000  27310.000000   \n",
       "mean       4.362110     60.654317      5.621359      0.839242      0.723612   \n",
       "std        0.985314     29.939369      1.308844      0.097361      0.101676   \n",
       "min        1.100000      5.360000      1.770000     -2.510000      0.290000   \n",
       "25%        3.730000     39.675000      4.620000      0.810000      0.650000   \n",
       "50%        4.310000     55.070000      5.530000      0.860000      0.710000   \n",
       "75%        4.840000     75.400000      6.560000      0.890000      0.790000   \n",
       "max       14.230000    493.920000     11.930000      3.510000      0.980000   \n",
       "\n",
       "         Uber index      Yule's K  \n",
       "count  27310.000000  27310.000000  \n",
       "mean      25.751004    175.234313  \n",
       "std       13.431118     96.680399  \n",
       "min        4.000000     11.340000  \n",
       "25%       18.750000    110.190000  \n",
       "50%       23.020000    152.000000  \n",
       "75%       28.560000    214.500000  \n",
       "max      251.780000   1564.100000  \n",
       "\n",
       "[8 rows x 56 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = StandardScaler().fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = df[df.columns[:ncol-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = StandardScaler().fit_transform(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27310, 56)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split x, y into train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import confusion_matrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "from mlxtend.evaluate import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dividing X, y into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost matrix is given by http://cap2018.litislab.fr/competition_en.pdf\n",
    "# Lower is better.\n",
    "def compute_performance_from_confusion_matrix(confusion_matrix):\n",
    "    cost_matrix = np.array([[0,1,2,3,4,6], [1,0,1,4,5,8],[3,2,0,3,5,8], [10,7,5,0,2,7], [20,16,12,4,0,8], [44,38,32,19,13,0]])\n",
    "    n = confusion_matrix.sum()\n",
    "    # Performance E = Dot product of cost matrix and confusion matrix / nb_sample\n",
    "    performance_E = np.vdot(cost_matrix, confusion_matrix)/n\n",
    "    return performance_E\n",
    "def compute_performance_from_predictions(ground_truth, predictions):\n",
    "    cm = confusion_matrix(np.ravel(ground_truth, order='C'), predictions)\n",
    "    cost_matrix = np.array([[0,1,2,3,4,6], [1,0,1,4,5,8],[3,2,0,3,5,8], [10,7,5,0,2,7], [20,16,12,4,0,8], [44,38,32,19,13,0]])\n",
    "    n = cm.sum()\n",
    "    # Performance E = Dot product of cost matrix and confusion matrix / nb_sample\n",
    "    performance_E = np.vdot(cost_matrix, cm)/n\n",
    "    return performance_E\n",
    "\n",
    "custom_loss = make_scorer(compute_performance_from_predictions, greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 70.3639\n",
    "svm_model = SVC(C = C, gamma=0.0097).fit(X_train,np.ravel(y_train,order='C'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8255711775043937\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4094903339191564"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_predictions = svm_model.predict(X_test)\n",
    "accuracy = svm_model.score(X_test, y_test)\n",
    "print(accuracy)\n",
    "# Result = 0.8255711775043937\n",
    "compute_performance_from_predictions(y_test, svm_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find hyperparameters for classifier\n",
    "**Random Forest, ExtraTreesClassifier, XGB Classifier, ... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n"
     ]
    }
   ],
   "source": [
    "from hpsklearn import HyperoptEstimator, any_sparse_classifier, tfidf, any_classifier\n",
    "from hyperopt import tpe\n",
    "import array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim = HyperoptEstimator( classifier=any_classifier('clf'),  \n",
    "                            algo=tpe.suggest, trial_timeout=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20482, 56)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim.fit( X_train, y_train.ravel(), verbose=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minh Tri\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "predictions = estim.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A2', 'B2', 'A1', ..., 'A1', 'A1', 'B2'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7989162272993556\n",
      "{'learner': XGBClassifier(base_score=0.5, booster='gbtree',\n",
      "       colsample_bylevel=0.5714319639165071,\n",
      "       colsample_bytree=0.8925838442029801, gamma=0.0034471649109639527,\n",
      "       learning_rate=0.0007174472831284953, max_delta_step=0, max_depth=6,\n",
      "       min_child_weight=9, missing=nan, n_estimators=200, n_jobs=1,\n",
      "       nthread=None, objective='multi:softprob', random_state=0,\n",
      "       reg_alpha=0.003530449335628467, reg_lambda=1.1119234618341498,\n",
      "       scale_pos_weight=1, seed=4, silent=True,\n",
      "       subsample=0.6378778357947126), 'preprocs': (), 'ex_preprocs': ()}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minh Tri\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4320445225541886"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print( estim.score( X_test, y_test.ravel()))\n",
    "print(estim.best_model())\n",
    "compute_performance_from_predictions(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_clf_best = estim.best_model()['learner']\n",
    "# xgbc_clf_best = XGBClassifier(base_score=0.5, booster='gbtree',\n",
    "#        colsample_bylevel=0.5714319639165071,\n",
    "#        colsample_bytree=0.8925838442029801, gamma=0.0034471649109639527,\n",
    "#        learning_rate=0.0007174472831284953, max_delta_step=0, max_depth=6,\n",
    "#        min_child_weight=9, missing=nan, n_estimators=200, n_jobs=1,\n",
    "#        nthread=None, objective='multi:softprob', random_state=0,\n",
    "#        reg_alpha=0.003530449335628467, reg_lambda=1.1119234618341498,\n",
    "#        scale_pos_weight=1, seed=4, silent=True,\n",
    "#        subsample=0.6378778357947126)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minh Tri\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.4320445225541886"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict =  xgbc_clf_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find hyper parameter for Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minh Tri\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform, conditional\n",
    "from keras import optimizers\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test):\n",
    "    '''\n",
    "    Model providing function:\n",
    "\n",
    "    Create Keras model with double curly brackets dropped-in as needed.\n",
    "    Return value has to be a valid python dictionary with two customary keys:\n",
    "        - loss: Specify a numeric evaluation metric to be minimized\n",
    "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
    "    The last one is optional, though recommended, namely:\n",
    "        - model: specify the model just created so that we can later use it again.\n",
    "    '''\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers.core import Dense, Dropout, Activation\n",
    "    from keras import optimizers\n",
    "    from keras.optimizers import RMSprop\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(784,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense({{choice([256, 512, 1024])}}))\n",
    "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "\n",
    "    # If we choose 'four', add an additional fourth layer\n",
    "    if conditional({{choice(['three', 'four'])}}) == 'four':\n",
    "        model.add(Dense(100))\n",
    "        # We can also choose between complete sets of layers\n",
    "        model.add({{choice([Dropout(0.5), Activation('linear')])}})\n",
    "        model.add(Activation('relu'))\n",
    "\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer={{choice(['adam', 'sgd'])}})\n",
    "\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size={{choice([32, 64, 128])}},\n",
    "              nb_epoch=1,\n",
    "              show_accuracy=True,\n",
    "              verbose=2,\n",
    "              validation_data=(X_test, Y_test))\n",
    "    score, acc = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test):\n",
    "    from keras import optimizers\n",
    "    '''\n",
    "    Model providing function:\n",
    "\n",
    "    Create Keras model with double curly brackets dropped-in as needed.\n",
    "    Return value has to be a valid python dictionary with two customary keys:\n",
    "        - loss: Specify a numeric evaluation metric to be minimized\n",
    "        - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
    "    The last one is optional, though recommended, namely:\n",
    "        - model: specify the model just created so that we can later use it again.\n",
    "    '''\n",
    "    model = Sequential()\n",
    "    model.add(Dense(50, input_shape=(784,)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense({{choice([50, 45, 40])}}))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout({{uniform(0, 1)}}))\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "#     rms = keras.optimizers.RMSprop()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size={{choice([64, 128])}},\n",
    "              nb_epoch=1,\n",
    "              verbose=2,\n",
    "              validation_data=(X_test, Y_test))\n",
    "    score, acc = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test accuracy:', acc)\n",
    "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.63279598,  0.99383952,  0.83642344, ..., -1.11741273,\n",
       "        -0.45350769, -0.35182867],\n",
       "       [ 0.51096503, -0.49421647, -0.56235902, ..., -0.33058453,\n",
       "        -0.57710354,  1.80614567],\n",
       "       [ 0.2305073 ,  0.94583771,  0.55775974, ..., -1.31411978,\n",
       "        -0.58082631, -0.10616941],\n",
       "       ...,\n",
       "       [ 0.51096503, -0.01419841, -0.28369533, ..., -0.52729158,\n",
       "        -0.48775714,  0.57722878],\n",
       "       [ 0.2305073 ,  0.39381694,  0.18074416, ..., -1.31411978,\n",
       "        -0.68953109,  0.98455768],\n",
       "       [ 2.19371145,  1.85787203,  1.75437443, ..., -1.11741273,\n",
       "        -0.27555945, -0.34779469]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Imports:\n",
      "#coding=utf-8\n",
      "\n",
      "try:\n",
      "    import pandas as pd\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import numpy as np\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import sklearn\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import StandardScaler\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.decomposition import PCA\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import matplotlib.pyplot as plt\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import seaborn as sns\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.ensemble import ExtraTreesClassifier\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.ensemble import RandomForestClassifier\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from xgboost import XGBClassifier\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from vecstack import stacking\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import accuracy_score\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from mlxtend.plotting import plot_confusion_matrix\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from mlxtend.evaluate import confusion_matrix\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import train_test_split\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.metrics import make_scorer\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.model_selection import cross_val_score\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.svm import SVC\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hpsklearn import HyperoptEstimator, any_sparse_classifier, tfidf, any_classifier\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    import array\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperopt import Trials, STATUS_OK, tpe\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas import optim\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from hyperas.distributions import choice, uniform, conditional\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import optimizers\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import RMSprop\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.models import Sequential\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.layers.core import Dense, Dropout, Activation\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import optimizers\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras.optimizers import RMSprop\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from keras import optimizers\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import LabelEncoder\n",
      "except:\n",
      "    pass\n",
      "\n",
      "try:\n",
      "    from sklearn.preprocessing import OneHotEncoder\n",
      "except:\n",
      "    pass\n",
      "\n",
      ">>> Hyperas search space:\n",
      "\n",
      "def get_space():\n",
      "    return {\n",
      "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
      "        'Dense': hp.choice('Dense', [256, 512, 1024]),\n",
      "        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\n",
      "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
      "        'conditional': hp.choice('conditional', ['three', 'four']),\n",
      "        'add': hp.choice('add', [Dropout(0.5), Activation('linear')]),\n",
      "        'optimizer': hp.choice('optimizer', ['adam', 'sgd']),\n",
      "        'batch_size': hp.choice('batch_size', [32, 64, 128]),\n",
      "    }\n",
      "\n",
      ">>> Data\n",
      "1: \n",
      "2: \n",
      "3: \n",
      "4: \n",
      ">>> Resulting replaced keras model:\n",
      "\n",
      "   1: def keras_fmin_fnct(space):\n",
      "   2: \n",
      "   3:     '''\n",
      "   4:     Model providing function:\n",
      "   5: \n",
      "   6:     Create Keras model with double curly brackets dropped-in as needed.\n",
      "   7:     Return value has to be a valid python dictionary with two customary keys:\n",
      "   8:         - loss: Specify a numeric evaluation metric to be minimized\n",
      "   9:         - status: Just use STATUS_OK and see hyperopt documentation if not feasible\n",
      "  10:     The last one is optional, though recommended, namely:\n",
      "  11:         - model: specify the model just created so that we can later use it again.\n",
      "  12:     '''\n",
      "  13: \n",
      "  14:     model = Sequential()\n",
      "  15:     model.add(Dense(512, input_shape=(784,)))\n",
      "  16:     model.add(Activation('relu'))\n",
      "  17:     model.add(Dropout(space['Dropout']))\n",
      "  18:     model.add(Dense(space['Dense']))\n",
      "  19:     model.add(Activation(space['Activation']))\n",
      "  20:     model.add(Dropout(space['Dropout_1']))\n",
      "  21: \n",
      "  22:     # If we choose 'four', add an additional fourth layer\n",
      "  23:     if conditional(space['conditional']) == 'four':\n",
      "  24:         model.add(Dense(100))\n",
      "  25:         # We can also choose between complete sets of layers\n",
      "  26:         model.add(space['add'])\n",
      "  27:         model.add(Activation('relu'))\n",
      "  28: \n",
      "  29:     model.add(Dense(10))\n",
      "  30:     model.add(Activation('softmax'))\n",
      "  31: \n",
      "  32:     model.compile(loss='categorical_crossentropy', optimizer=space['optimizer'])\n",
      "  33: \n",
      "  34:     model.fit(X_train, Y_train,\n",
      "  35:               batch_size=space['batch_size'],\n",
      "  36:               nb_epoch=1,\n",
      "  37:               show_accuracy=True,\n",
      "  38:               verbose=2,\n",
      "  39:               validation_data=(X_test, Y_test))\n",
      "  40:     score, acc = model.evaluate(X_test, Y_test, show_accuracy=True, verbose=0)\n",
      "  41:     print('Test accuracy:', acc)\n",
      "  42:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
      "  43: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-ddc0e22a1946>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m                                       \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                                       \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                                       notebook_name='Untitled')\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mminimize\u001b[1;34m(model, data, algo, max_evals, trials, functions, rseed, notebook_name, verbose, eval_space, return_space)\u001b[0m\n\u001b[0;32m     65\u001b[0m                                      \u001b[0mfull_model_string\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                                      \u001b[0mnotebook_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnotebook_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                                      verbose=verbose)\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     \u001b[0mbest_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperas\\optim.py\u001b[0m in \u001b[0;36mbase_minimizer\u001b[1;34m(model, data, functions, algo, max_evals, trials, rseed, full_model_string, notebook_name, verbose, stack)\u001b[0m\n\u001b[0;32m    131\u001b[0m              \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m              \u001b[0mrstate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomState\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m              return_argmin=True),\n\u001b[0m\u001b[0;32m    134\u001b[0m         \u001b[0mget_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     )\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    305\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 307\u001b[1;33m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m         )\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             return_argmin=return_argmin)\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin)\u001b[0m\n\u001b[0;32m    318\u001b[0m                     verbose=verbose)\n\u001b[0;32m    319\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    171\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m                 \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m     90\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Google Drive\\sync_P17_temp\\P18\\TX2\\temp_model.py\u001b[0m in \u001b[0;36mkeras_fmin_fnct\u001b[1;34m(space)\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "def datasets():\n",
    "    return X_train, y_train.ravel(), X_test, y_test.ravel()\n",
    "X_train, Y_train, X_test, Y_test = datasets()\n",
    "trials = Trials()\n",
    "# best_run, best_model = optim.minimize(model=model,\n",
    "#                                           data=datasets,\n",
    "#                                           algo=tpe.suggest,\n",
    "#                                           max_evals=5,\n",
    "#                                           trials=trials)\n",
    "if __name__ == '__main__':\n",
    "    best_run, best_model = optim.minimize(model=model,\n",
    "                                      data=datasets,\n",
    "                                      algo=tpe.suggest,\n",
    "                                      max_evals=5,\n",
    "                                      trials=Trials(),\n",
    "                                      notebook_name='Untitled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ExtraTreesClassifier(random_state=0, \n",
    "                         n_estimators=200),\n",
    "        \n",
    "    RandomForestClassifier(random_state=0, \n",
    "                           n_estimators=200),\n",
    "        \n",
    "    xgbc_clf_best,\n",
    "    SVC(C = C, gamma=0.0097)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import argmax\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "label_encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_encoded = label_encoder.fit_transform(y_train.flatten())\n",
    "y_test_encoded = label_encoder.fit_transform(y_test.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task:         [classification]\n",
      "n_classes:    [6]\n",
      "metric:       [accuracy_score]\n",
      "mode:         [oof_pred_bag]\n",
      "n_models:     [4]\n",
      "\n",
      "model  0:     [ExtraTreesClassifier]\n",
      "    fold  0:  [0.78219512]\n",
      "    fold  1:  [0.77568953]\n",
      "    fold  2:  [0.79023199]\n",
      "    fold  3:  [0.77289377]\n",
      "    fold  4:  [0.77728938]\n",
      "    ----\n",
      "    MEAN:     [0.77965996] + [0.00608868]\n",
      "    FULL:     [0.77966019]\n",
      "\n",
      "model  1:     [RandomForestClassifier]\n",
      "    fold  0:  [0.80487805]\n",
      "    fold  1:  [0.79741274]\n",
      "    fold  2:  [0.80610501]\n",
      "    fold  3:  [0.79609280]\n",
      "    fold  4:  [0.79902320]\n",
      "    ----\n",
      "    MEAN:     [0.80070236] + [0.00403768]\n",
      "    FULL:     [0.80070306]\n",
      "\n",
      "model  2:     [XGBClassifier]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minh Tri\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Minh Tri\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  0:  [0.78780488]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minh Tri\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Minh Tri\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  1:  [0.78911399]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minh Tri\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Minh Tri\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  2:  [0.79023199]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minh Tri\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Minh Tri\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  3:  [0.78217338]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minh Tri\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\Users\\Minh Tri\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    fold  4:  [0.78778999]\n",
      "    ----\n",
      "    MEAN:     [0.78742284] + [0.00277809]\n",
      "    FULL:     [0.78742310]\n",
      "\n",
      "model  3:     [SVC]\n",
      "    fold  0:  [0.81463415]\n",
      "    fold  1:  [0.80693190]\n",
      "    fold  2:  [0.81489621]\n",
      "    fold  3:  [0.79975580]\n",
      "    fold  4:  [0.80439560]\n",
      "    ----\n",
      "    MEAN:     [0.80812273] + [0.00589226]\n",
      "    FULL:     [0.80812421]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "S_train, S_test = stacking(models,                     # list of models\n",
    "                           X_train, y_train_encoded.ravel(), X_test,   # data\n",
    "                           regression=False,           # classification task (if you need \n",
    "                                                       #     regression - set to True)\n",
    "                           mode='oof_pred_bag',        # mode: oof for train set, predict test \n",
    "                                                       #     set in each fold and vote\n",
    "                           needs_proba=False,          # predict class labels (if you need \n",
    "                                                       #     probabilities - set to True) \n",
    "                           save_dir=None,              # do not save result and log (to save \n",
    "                                                       #     in current dir - set to '.')\n",
    "                           metric=accuracy_score,      # metric: callable\n",
    "                           n_folds=5,                  # number of folds\n",
    "                           stratified=True,            # stratified split for folds\n",
    "                           shuffle=True,               # shuffle the data\n",
    "                           random_state=0,             # ensure reproducibility\n",
    "                           verbose=2)                  # print all info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2, 2],\n",
       "       [0, 0, 0],\n",
       "       [2, 2, 2],\n",
       "       [0, 0, 0],\n",
       "       [1, 1, 1]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked model : 2nd layer, naive (defauilt) model with XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final prediction score: [0.82776801]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Minh Tri\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "# Initialize 2nd level model\n",
    "model = XGBClassifier(random_state=0, learning_rate=0.01, \n",
    "                      n_estimators=100)\n",
    "    \n",
    "# Fit 2nd level model\n",
    "model = model.fit(S_train, y_train_encoded)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(S_test)\n",
    "\n",
    "# Final prediction score\n",
    "print('Final prediction score: [%.8f]' % accuracy_score(y_test_encoded, y_pred))\n",
    "# Final prediction score: [0.82776801]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 0, 2, ..., 1, 1, 3], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3961628588166374"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_performance_from_predictions(y_test_encoded, y_pred)\n",
    "# 0.3961628588166374"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best stacked 2nd layer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_stacked = HyperoptEstimator( classifier=any_classifier('clf'),  \n",
    "                            algo=tpe.suggest, trial_timeout=500, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20482, 56)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TERMINATING DUE TO TIMEOUT\n",
      "Training learner ExtraTreesClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "           max_depth=None, max_features=0.16979995312295992,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=98, n_jobs=1, oob_score=False, random_state=0,\n",
      "           verbose=False, warm_start=False) on X/EX of dimension (20482, 4)\n"
     ]
    }
   ],
   "source": [
    "estim_stacked.fit( S_train, y_train_encoded.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_2nd_layer = estim_stacked.best_model()['learner']\n",
    "# stacked_2nd_layer_best = ExtraTreesClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
    "#            max_depth=None, max_features=0.16979995312295992,\n",
    "#            max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
    "#            min_impurity_split=None, min_samples_leaf=1,\n",
    "#            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "#            n_estimators=98, n_jobs=1, oob_score=False, random_state=0,\n",
    "#            verbose=False, warm_start=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = stacked_2nd_layer.predict(S_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 0, ..., 0, 0, 3], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "ExtraTreesClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "           max_depth=None, max_features=0.16979995312295992,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=98, n_jobs=1, oob_score=False, random_state=0,\n",
      "           verbose=False, warm_start=False)\n",
      "0.38927943760984185\n",
      "0.8302577621558289\n"
     ]
    }
   ],
   "source": [
    "print( estim_stacked.score( S_test, predictions))\n",
    "print(estim_stacked.best_model()['learner'])\n",
    "print(compute_performance_from_predictions(y_test_encoded, predictions))\n",
    "# 0.38927943760984185\n",
    "print(accuracy_score(y_test_encoded, predictions))\n",
    "# 0.8302577621558289"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "estim_stacked_xgboost = HyperoptEstimator( classifier=any_classifier('xgboost'),  \n",
    "                            algo=tpe.suggest, trial_timeout=500, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training learner GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.06765575510106916, loss='deviance',\n",
      "              max_depth=None, max_features=0.9879187105689301,\n",
      "              max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "              min_impurity_split=None, min_samples_leaf=7,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=19, presort='auto', random_state=1,\n",
      "              subsample=0.6326695839978682, verbose=0, warm_start=False) on X/EX of dimension (20482, 4)\n"
     ]
    }
   ],
   "source": [
    "estim_xgboost = estim_stacked_xgboost.fit( S_train, y_train_encoded.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8161800605409628\n",
      "1.0\n",
      "0.3835676625659051\n",
      "0.830697129466901\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_train_encoded.ravel(), estim_stacked_xgboost.predict(S_train)))\n",
    "prediction = estim_stacked_xgboost.predict(S_test)\n",
    "print( estim_stacked_xgboost.score( S_test, prediction))\n",
    "# print(estim_stacked.best_model()['learner'])\n",
    "print(compute_performance_from_predictions(y_test_encoded, prediction))\n",
    "# 0.3835676625659051\n",
    "print(accuracy_score(y_test_encoded, prediction))\n",
    "# 0.830697129466901"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
